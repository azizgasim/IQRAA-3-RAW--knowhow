# ğŸ¤– ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ (Backend)
## Ù…Ø¹ Ø¯Ø±ÙˆØ³ Ø¢Ø¨Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ù„Ù€ Backend
### Ù„Ù„Ù†Ø³Ø® ÙˆØ§Ù„Ù„ØµÙ‚ Ù…Ø¨Ø§Ø´Ø±Ø©

---

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     ğŸ¯ Ù…Ù‡Ù…Ø© Ø¥Ù†Ø´Ø§Ø¡ FastAPI + ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±ÙˆØ³ Ø§Ù„Ø¢Ø¨Ø§Ø¡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. Ø¥Ù†Ø´Ø§Ø¡ FastAPI ÙŠØªØµÙ„ Ø¨Ù€ diwan_iqraa_elmi Ù…Ø¨Ø§Ø´Ø±Ø© (157M ØµÙ)
2. Ø¥Ø¶Ø§ÙØ© Report Generator
3. ØªØ·Ø¨ÙŠÙ‚ Ø¯Ø±ÙˆØ³ Ø¢Ø¨Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ù„Ù€ Backend

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                Ø§Ù„Ø¬Ø²Ø¡ 1: Ø¥Ù†Ø´Ø§Ø¡ FastAPI
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1ï¸âƒ£ Ø£Ù†Ø´Ø¦: backend/main.py

"""
IQRA-12 Backend API v2.1
FastAPI Ù…Ø¹ Ø§ØªØµØ§Ù„ Ù…Ø¨Ø§Ø´Ø± Ø¨Ù€ diwan_iqraa_elmi
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from google.cloud import bigquery
from datetime import datetime
import asyncio
import hashlib

app = FastAPI(
    title="IQRA-12 API",
    description="Backend API - 157M+ Islamic texts",
    version="2.1.0"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:3001"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BigQuery Client + Cache (Ø¯Ø±Ø³ Chen: Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…Ù‡Ù…)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

bq_client = bigquery.Client(project="iqraa-12")

# Cache Ø¨Ø³ÙŠØ· Ù„Ù„Ù†ØªØ§Ø¦Ø¬ (Ø¯Ø±Ø³ Kaneko: Ø§Ø­ØªØ±Ù… Ø§Ù„Ø£Ø¯Ø§Ø¡)
_cache: Dict[str, Any] = {}
_cache_ttl = 300  # 5 Ø¯Ù‚Ø§Ø¦Ù‚

def get_cache_key(query: str, corpus: str, limit: int) -> str:
    return hashlib.md5(f"{query}:{corpus}:{limit}".encode()).hexdigest()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ØªØ§Ø­Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DIWAN_TABLES = {
    "fiqh": {
        "table": "iqraa-12.diwan_iqraa_elmi.01_fiqh_rulings",
        "count": 47194044,
        "icon": "ğŸ“–",
        "label_ar": "Ø§Ù„ÙÙ‚Ù‡"
    },
    "hadith": {
        "table": "iqraa-12.diwan_iqraa_elmi.02_hadith_corpus",
        "count": 41090793,
        "icon": "ğŸ“œ",
        "label_ar": "Ø§Ù„Ø­Ø¯ÙŠØ«"
    },
    "timeline": {
        "table": "iqraa-12.diwan_iqraa_elmi.03_timeline_events",
        "count": 38857627,
        "icon": "ğŸ•",
        "label_ar": "Ø§Ù„ØªØ§Ø±ÙŠØ®"
    },
    "kalam": {
        "table": "iqraa-12.diwan_iqraa_elmi.04_kalam_schools",
        "count": 40886753,
        "icon": "ğŸ’­",
        "label_ar": "Ø§Ù„ÙƒÙ„Ø§Ù…"
    },
    "usul": {
        "table": "iqraa-12.diwan_iqraa_elmi.05_usul_and_maqasid",
        "count": 26245012,
        "icon": "âš–ï¸",
        "label_ar": "Ø§Ù„Ø£ØµÙˆÙ„"
    },
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Models (Ø¯Ø±Ø³ Friedman: Ø¹Ù‚ÙˆØ¯ API ÙˆØ§Ø¶Ø­Ø©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SearchRequest(BaseModel):
    query: str
    corpus: Optional[str] = "all"  # Ø¯Ø±Ø³ Chen: Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¢Ù…Ù†
    limit: int = 20

class SearchResponse(BaseModel):
    success: bool
    query: str
    corpus: str
    results: List[Dict[str, Any]]
    total: int
    latency_ms: int
    cached: bool = False
    source: str = "diwan_iqraa_elmi"

class ReportRequest(BaseModel):
    research_question: str
    corpus: Optional[str] = None
    format: str = "MARKDOWN"

class PipelineRequest(BaseModel):
    query: str
    mode: str = "full"  # search | analyze | full

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Logging (Ø¯Ø±Ø³ Harris: Command logging Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def log_search(query: str, corpus: str, results_count: int, latency_ms: int):
    """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"""
    try:
        log_query = """
        INSERT INTO `iqraa-12.ops.search_logs` 
        (timestamp, query, corpus, results_count, latency_ms)
        VALUES (@ts, @query, @corpus, @count, @latency)
        """
        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("ts", "TIMESTAMP", datetime.utcnow()),
                bigquery.ScalarQueryParameter("query", "STRING", query[:500]),
                bigquery.ScalarQueryParameter("corpus", "STRING", corpus),
                bigquery.ScalarQueryParameter("count", "INT64", results_count),
                bigquery.ScalarQueryParameter("latency", "INT64", latency_ms),
            ]
        )
        bq_client.query(log_query, job_config=job_config)
    except:
        pass  # Ù„Ø§ ØªÙØ´Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨Ø³Ø¨Ø¨ Ø§Ù„ØªØ³Ø¬ÙŠÙ„

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¨Ø­Ø« (Ø¯Ø±Ø³ Norman: ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© ÙÙˆØ±ÙŠØ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/api/search", response_model=SearchResponse)
async def search(request: SearchRequest, background_tasks: BackgroundTasks):
    """
    Ø§Ù„Ø¨Ø­Ø« ÙÙŠ diwan_iqraa_elmi
    ÙŠØ¯Ø¹Ù…: fiqh, hadith, kalam, usul, timeline, Ø£Ùˆ all
    """
    import time
    start_time = time.time()
    
    try:
        # ÙØ­Øµ Ø§Ù„Ù€ Cache
        cache_key = get_cache_key(request.query, request.corpus, request.limit)
        if cache_key in _cache:
            cached = _cache[cache_key]
            if time.time() - cached["time"] < _cache_ttl:
                cached["data"]["cached"] = True
                return SearchResponse(**cached["data"])
        
        results = []
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        if request.corpus and request.corpus != "all":
            if request.corpus not in DIWAN_TABLES:
                raise HTTPException(
                    status_code=400, 
                    detail=f"Ù…ØµØ¯Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {request.corpus}. Ø§Ù„Ù…ØªØ§Ø­: {list(DIWAN_TABLES.keys())}"
                )
            tables = {request.corpus: DIWAN_TABLES[request.corpus]}
        else:
            tables = DIWAN_TABLES
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ ÙƒÙ„ Ø¬Ø¯ÙˆÙ„
        limit_per_table = max(5, request.limit // len(tables))
        
        for corpus_name, corpus_info in tables.items():
            # Ù…Ø­Ø§ÙˆÙ„Ø© SEARCH Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø«Ù… LIKE ÙƒØ¨Ø¯ÙŠÙ„
            query = f"""
            SELECT 
                CAST(id AS STRING) as id,
                SUBSTR(content, 1, 500) as content,
                COALESCE(title, book_name, '') as title,
                COALESCE(author, '') as author,
                '{corpus_name}' as corpus,
                '{corpus_info["icon"]}' as corpus_icon,
                '{corpus_info["label_ar"]}' as corpus_label
            FROM `{corpus_info["table"]}`
            WHERE content LIKE CONCAT('%', @query, '%')
            LIMIT @limit
            """
            
            job_config = bigquery.QueryJobConfig(
                query_parameters=[
                    bigquery.ScalarQueryParameter("query", "STRING", request.query),
                    bigquery.ScalarQueryParameter("limit", "INT64", limit_per_table),
                ]
            )
            
            try:
                job = bq_client.query(query, job_config=job_config)
                for row in job.result():
                    results.append({
                        "id": row.id,
                        "content": row.content,
                        "title": row.title,
                        "author": row.author,
                        "corpus": row.corpus,
                        "corpus_icon": row.corpus_icon,
                        "corpus_label": row.corpus_label,
                    })
            except Exception as e:
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ù„ÙƒÙ† Ù„Ø§ ØªÙØ´Ù„ (Ø¯Ø±Ø³ Chen: Ø§Ù„ØªØ³Ø§Ù…Ø­)
                print(f"Error searching {corpus_name}: {e}")
        
        # ØªØ±ØªÙŠØ¨ ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results = results[:request.limit]
        
        latency_ms = int((time.time() - start_time) * 1000)
        
        response_data = {
            "success": True,
            "query": request.query,
            "corpus": request.corpus,
            "results": results,
            "total": len(results),
            "latency_ms": latency_ms,
            "cached": False,
            "source": "diwan_iqraa_elmi"
        }
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ù€ Cache
        _cache[cache_key] = {"data": response_data, "time": time.time()}
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© (Ø¯Ø±Ø³ Harris: Ù„Ø§ ØªØ¨Ø·Ø¦ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©)
        background_tasks.add_task(
            log_search, request.query, request.corpus, len(results), latency_ms
        )
        
        return SearchResponse(**response_data)
        
    except HTTPException:
        raise
    except Exception as e:
        # Ø¯Ø±Ø³ Norman: Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ Ù…ÙÙŠØ¯Ø©
        raise HTTPException(
            status_code=500, 
            detail=f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø«. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰. ({str(e)[:100]})"
        )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª (Ø¯Ø±Ø³ Friedman: Ø§Ù„Ø´ÙØ§ÙÙŠØ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/api/stats")
async def get_stats():
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    stats = {
        "source": "diwan_iqraa_elmi",
        "corpora": {},
        "total_records": 0
    }
    
    for corpus_name, corpus_info in DIWAN_TABLES.items():
        stats["corpora"][corpus_name] = {
            "count": corpus_info["count"],
            "icon": corpus_info["icon"],
            "label_ar": corpus_info["label_ar"],
            "table": corpus_info["table"]
        }
        stats["total_records"] += corpus_info["count"]
    
    stats["total_formatted"] = f"{stats['total_records']:,}"
    
    return stats

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pipeline (Ø¯Ø±Ø³ Harris: Ø£ÙˆØ§Ù…Ø± ÙƒÙ€ Domain Actions)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.post("/api/pipeline")
async def run_pipeline(request: PipelineRequest, background_tasks: BackgroundTasks):
    """
    Pipeline ÙƒØ§Ù…Ù„: Ø¨Ø­Ø« â†’ ØªØ¬Ù…ÙŠØ¹ â†’ ØªÙ‚Ø±ÙŠØ±
    modes: search, analyze, full
    """
    import time
    start_time = time.time()
    
    results = {
        "query": request.query,
        "mode": request.mode,
        "stages": {}
    }
    
    try:
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¨Ø­Ø«
        if request.mode in ["search", "full"]:
            search_result = await search(
                SearchRequest(query=request.query, corpus="all", limit=10),
                background_tasks
            )
            results["stages"]["search"] = {
                "status": "success",
                "count": search_result.total,
                "results": search_result.results
            }
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ù„Ù„Ù€ full)
        if request.mode == "full":
            search_results = results["stages"].get("search", {}).get("results", [])
            
            # ØªÙ‚Ø±ÙŠØ± Ø¨Ø³ÙŠØ·
            report_lines = [
                f"# ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ",
                f"## Ø§Ù„Ø³Ø¤Ø§Ù„: {request.query}",
                "",
                f"ØªÙ… Ø§Ù„Ø¨Ø­Ø« ÙÙŠ {len(DIWAN_TABLES)} Ù…ØµØ§Ø¯Ø± ({sum(t['count'] for t in DIWAN_TABLES.values()):,} Ù†Øµ)",
                "",
                "## Ø§Ù„Ù†ØªØ§Ø¦Ø¬",
                ""
            ]
            
            # ØªØ¬Ù…ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ù…ØµØ¯Ø±
            by_corpus = {}
            for r in search_results:
                corpus = r.get("corpus", "other")
                if corpus not in by_corpus:
                    by_corpus[corpus] = []
                by_corpus[corpus].append(r)
            
            for corpus, items in by_corpus.items():
                corpus_info = DIWAN_TABLES.get(corpus, {})
                icon = corpus_info.get("icon", "ğŸ“„")
                label = corpus_info.get("label_ar", corpus)
                
                report_lines.append(f"### {icon} {label}")
                report_lines.append("")
                
                for i, item in enumerate(items[:3], 1):
                    content = item.get("content", "")[:200]
                    title = item.get("title", "")
                    author = item.get("author", "")
                    
                    report_lines.append(f"**{i}.** {content}...")
                    if title or author:
                        report_lines.append(f"   â€” *{title}* {'Ù„Ù€ ' + author if author else ''}")
                    report_lines.append("")
            
            report_lines.append("---")
            report_lines.append(f"*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ {datetime.now().strftime('%Y-%m-%d %H:%M')}*")
            
            results["stages"]["report"] = {
                "status": "success",
                "content": "\n".join(report_lines),
                "format": "MARKDOWN"
            }
        
        latency_ms = int((time.time() - start_time) * 1000)
        results["latency_ms"] = latency_ms
        results["success"] = True
        
        return results
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Health & Info (Ø¯Ø±Ø³ Chen: Diagnostics ÙˆØ§Ø¶Ø­Ø©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.get("/")
async def root():
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª API"""
    return {
        "name": "IQRA-12 API",
        "version": "2.1.0",
        "description": "Ù…Ù†ØµØ© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ØªØ±Ø§Ø« Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠ",
        "data_source": "diwan_iqraa_elmi",
        "total_records": "157M+",
        "corpora": list(DIWAN_TABLES.keys()),
        "endpoints": {
            "search": "POST /api/search",
            "stats": "GET /api/stats",
            "pipeline": "POST /api/pipeline",
            "health": "GET /health"
        }
    }

@app.get("/health")
async def health():
    """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    checks = {
        "api": True,
        "bigquery": False,
        "cache_size": len(_cache)
    }
    
    try:
        list(bq_client.query("SELECT 1").result())
        checks["bigquery"] = True
    except Exception as e:
        checks["bigquery_error"] = str(e)[:100]
    
    status = "healthy" if all([checks["api"], checks["bigquery"]]) else "degraded"
    
    return {
        "status": status,
        "checks": checks,
        "timestamp": datetime.utcnow().isoformat()
    }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªØ´ØºÙŠÙ„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

2ï¸âƒ£ Ø­Ø¯Ù‘Ø«: backend/requirements.txt

Ø£Ø¶Ù:
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.5.0
python-multipart>=0.0.6

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

3ï¸âƒ£ Ø£Ù†Ø´Ø¦ Ø¬Ø¯ÙˆÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹):

CREATE TABLE IF NOT EXISTS `iqraa-12.ops.search_logs` (
  timestamp TIMESTAMP,
  query STRING,
  corpus STRING,
  results_count INT64,
  latency_ms INT64
);

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     Ø§Ù„Ø¬Ø²Ø¡ 2: Ø¯Ø±ÙˆØ³ Ø¢Ø¨Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ù„Ù€ Backend
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ØªÙ… ØªØ¶Ù…ÙŠÙ†Ù‡Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø£Ø¹Ù„Ø§Ù‡:

Ù…Ù† Jon Friedman (Microsoft):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… "Ø¹Ù‚ÙˆØ¯ API Ø­ÙˆÙ„ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ø§ Ø¬Ø¯Ø§ÙˆÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
   â†’ SearchRequest/SearchResponse ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©

âœ… "Feature Flags Ù„ØªØ¬Ø§Ø±Ø¨ A/B"
   â†’ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© corpus Ø¬Ø¯ÙŠØ¯ Ø¨Ø³Ù‡ÙˆÙ„Ø©

âœ… "Ø§Ù„Ø®ØµÙˆØµÙŠØ© Ø¬Ø²Ø¡ Ù…Ù† UX"
   â†’ Ù„Ø§ Ù†Ø³Ø¬Ù„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø´Ø®ØµÙŠØ©ØŒ ÙÙ‚Ø· Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ù…Ù† Steve Kaneko (Windows):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… "Ø§Ø­ØªØ±Ù… Ø§Ù„Ø£Ø¯Ø§Ø¡"
   â†’ Cache Ù„Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©

âœ… "Source of Truth ÙˆØ§Ø¶Ø­"
   â†’ diwan_iqraa_elmi Ù‡Ùˆ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„ÙˆØ­ÙŠØ¯

âœ… "Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„ØŒ Ù‚Ø¯Ù‘Ù… Ø¥Ø¬Ø±Ø§Ø¡ Ø¥ØµÙ„Ø§Ø­ÙŠ"
   â†’ Ø±Ø³Ø§Ø¦Ù„ Ø®Ø·Ø£ ÙˆØ§Ø¶Ø­Ø© Ù…Ø¹ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ù…Ù† Jensen Harris (Office):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… "Commands ÙƒÙ€ Domain Actions"
   â†’ ÙƒÙ„ endpoint Ù„Ù‡ Ù…Ø¹Ù†Ù‰ ÙˆØ§Ø¶Ø­ (search, pipeline, stats)

âœ… "Command logging Ù„Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"
   â†’ log_search() ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©

âœ… "Ù†ØªÙŠØ¬Ø© Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙ„ Ø£Ù…Ø±"
   â†’ success + error messages ÙˆØ§Ø¶Ø­Ø©

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ù…Ù† Raymond Chen (Windows):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… "Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¢Ù…Ù†"
   â†’ corpus: "all", limit: 20

âœ… "Race conditions"
   â†’ Cache ÙŠØ­Ù…ÙŠ Ù…Ù† Ø·Ù„Ø¨Ø§Øª Ù…ØªÙƒØ±Ø±Ø©

âœ… "Backward compatibility"
   â†’ API Ù…Ø³ØªÙ‚Ø±ØŒ Ø¥Ø¶Ø§ÙØ§Øª Ù„Ø§ ØªÙƒØ³Ø± Ø§Ù„Ù‚Ø¯ÙŠÙ…

âœ… "Ø£Ø®Ø·Ø§Ø¡ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù†Ø³Ø®"
   â†’ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Ù…Ù† Don Norman (Apple):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… "ØªØºØ°ÙŠØ© Ø±Ø§Ø¬Ø¹Ø© ÙÙˆØ±ÙŠØ©"
   â†’ latency_ms ÙÙŠ ÙƒÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø©

âœ… "Ø§Ù„ØªØ³Ø§Ù…Ø­: ØªØ£Ø®ÙŠØ± Ø§Ù„Ø´Ø¨ÙƒØ© Ù„Ø§ ÙŠÙØ³Ø¯ Ø§Ù„Ø­Ø§Ù„Ø©"
   â†’ Cache + Background tasks

âœ… "Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ø±Ø¦ÙŠØ©"
   â†’ /health endpoint Ù…ÙØµÙ„

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                Ø§Ù„Ø¬Ø²Ø¡ 3: Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

4ï¸âƒ£ ØªØ´ØºÙŠÙ„:

cd backend
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload --port 8000

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

5ï¸âƒ£ Ø§Ø®ØªØ¨Ø§Ø±:

# ÙØ­Øµ Ø§Ù„ØµØ­Ø©
curl http://localhost:8000/health

# Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
curl http://localhost:8000/api/stats

# Ø¨Ø­Ø« Ø¨Ø³ÙŠØ·
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "Ø­ÙƒÙ… Ø§Ù„Ø²ÙƒØ§Ø©", "limit": 5}'

# Ø¨Ø­Ø« ÙÙŠ Ù…ØµØ¯Ø± Ù…Ø­Ø¯Ø¯
curl -X POST http://localhost:8000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "ØµÙ„Ø§Ø© Ø§Ù„Ø¬Ù…Ø§Ø¹Ø©", "corpus": "fiqh", "limit": 10}'

# Pipeline ÙƒØ§Ù…Ù„
curl -X POST http://localhost:8000/api/pipeline \
  -H "Content-Type: application/json" \
  -d '{"query": "Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØµÙŠØ§Ù…", "mode": "full"}'

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

6ï¸âƒ£ Ø±ÙØ¹ Ø¥Ù„Ù‰ GitHub:

git add .
git commit -m "feat: FastAPI backend with diwan_iqraa_elmi integration"
git push

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†ÙÙŠØ°ØŒ Ø£Ø±Ø³Ù„:

âœ… Ø§Ù„Ù…Ù„ÙØ§Øª:
   - [ ] main.py (FastAPI)
   - [ ] requirements.txt (Ù…Ø­Ø¯Ø«)

âœ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:
   - [ ] /health: âœ…/âŒ
   - [ ] /api/stats: âœ…/âŒ
   - [ ] /api/search: âœ…/âŒ
   - [ ] /api/pipeline: âœ…/âŒ

âœ… Ø¯Ø±ÙˆØ³ Ø§Ù„Ø¢Ø¨Ø§Ø¡ Ø§Ù„Ù…Ø·Ø¨Ù‚Ø©:
   - [ ] Cache (Kaneko)
   - [ ] Logging (Harris)
   - [ ] Error messages (Chen)
   - [ ] Latency tracking (Norman)

âœ… GitHub:
   - [ ] ØªÙ… Ø§Ù„Ø±ÙØ¹

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ù€ Dashboard Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ port 8000.
Ø¨Ø¹Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ BackendØŒ Ø³Ù†Ø®ØªØ¨Ø± Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹Ø§Ù‹.

Ø´ÙƒØ±Ø§Ù‹! ğŸš€
```
