"""
Smart Distributor - ÙŠÙÙˆØ²Ù‘Ø¹ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
"""

import asyncio
import json
from google.cloud import bigquery
from transformers import AutoTokenizer, AutoModel
import torch
from datetime import datetime
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/user/distribution.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


class SmartDistributor:
    """Ù…ÙˆØ²Ø¹ Ø°ÙƒÙŠ - ÙŠØªØ¬Ù†Ø¨ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ù…Ù„ÙˆØ¡Ø©"""
    
    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ù…Ù„ÙˆØ¡Ø© (Ù†ØªØ¬Ù†Ø¨Ù‡Ø§)
    FILLED_TABLES = [
        "01_fiqh_rulings",
        "02_hadith_corpus",
        "03_timeline_events",
        "04_kalam_schools",
        "05_usul_and_maqasid",
        "06_geography_knowledge",
        "08_economy_segments",
        "09_sufism_spirituality",
        "10_philosophy_logic",
        "11_rulers_segments"
    ]
    
    # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª â†’ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©
    DOMAIN_TO_EMPTY_TABLE = {
        "Ø§Ù‚ØªØµØ§Ø¯": "economic_distress_famines_taxation_and_public_grievances",
        "Ø­Ø¶Ø±ÙŠ": "urban_life_and_city_rhythms",
        "Ø¹Ù…Ø§Ø±Ø©": "architectural_spaces_homes_markets_gardens_and_mosques",
        "ØªØ¬Ø§Ø±Ø©": "merchants_trade_networks_and_hidden_economies",
        "Ù‚Ø¶Ø§Ø¡": "judicial_practices_courtroom_dramas_and_legal_politics",
        "Ø­Ø±Ø¨": "warfare_experience_battlefields_and_emotional_histories",
        "Ø¨Ø­Ø±ÙŠ": "maritime_life_ports_seafaring_and_pirate_narratives",
        "Ø§Ø­ØªÙØ§Ù„Ø§Øª": "festivals_celebrations_and_public_spectacles",
        "Ø·Ø¹Ø§Ù…": "foodways_culinary_cultures_and_gastronomic_memory",
        "Ù†Ø³ÙŠØ¬": "textile_world_weaving_dyes_looms_and_female_economies",
        "Ù…ÙˆØ³ÙŠÙ‚Ù‰": "musical_traditions_instruments_singers_and_city_soundscapes",
        "Ø¹Ø·ÙˆØ±": "perfumery_incense_unguents_and_aromatic_cultures",
        "Ø´Ø±Ø·Ø©": "policing_night_patrols_surveillance_and_moral_order",
        "Ù…ÙˆØª": "death_burial_rituals_grief_cultures_and_afterlife_imaginations",
        "Ø²ÙˆØ§Ø¬": "marriage_customs_intimacies_conflicts_and_hidden_economies",
        "Ø·ÙÙˆÙ„Ø©": "childhood_worlds_play_learning_and_city_innocence",
        "ØµØ­Ø©": "body_health_medicine_healers_and_hidden_remedies",
        "Ø­Ù…Ø§Ù…Ø§Øª": "bathhouses_hygiene_beauty_and_gendered_spaces",
        "Ø³Ø­Ø±": "magic_sorcery_omens_divination_and_occult_practices",
        "Ù…ÙˆØ§Ø³Ù…": "seasonal_life_rhythms_festivities_migrations_and_city_tempos",
        
        # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ (Ù„Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©)
        "ØºÙŠØ± Ù…Ø­Ø¯Ø¯": "02_analysis_results"
    }
    
    def __init__(self):
        self.bq_client = bigquery.Client(project="iqraa-12")
        
        logger.info("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ CAMeLBERT-CA...")
        self.tokenizer = AutoTokenizer.from_pretrained("CAMeL-Lab/bert-base-arabic-camelbert-ca")
        self.model = AutoModel.from_pretrained("CAMeL-Lab/bert-base-arabic-camelbert-ca")
        self.model.eval()
        
        self.tracker = {
            "started_at": datetime.now().isoformat(),
            "processed": 0,
            "distributed": 0,
            "skipped": 0
        }
        
        logger.info("âœ… Smart Distributor Ø¬Ø§Ù‡Ø²")
    
    def get_target_table(self, domain: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ (ÙØ§Ø±Øº ÙÙ‚Ø·)"""
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø®Ø±ÙŠØ·Ø©
        table_name = self.DOMAIN_TO_EMPTY_TABLE.get(domain)
        
        if table_name:
            return f"iqraa-12.diwan_iqraa_v2.{table_name}"
        
        # Ø§ÙØªØ±Ø§Ø¶ÙŠ
        return "iqraa-12.diwan_iqraa_v2.02_analysis_results"
    
    def simple_classify(self, text: str) -> str:
        """ØªØµÙ†ÙŠÙ Ø¨Ø³ÙŠØ·"""
        text_lower = text.lower()
        
        # ØªØµÙ†ÙŠÙ Ù…ÙˆØ³Ø¹
        if any(w in text_lower for w in ["Ø¶Ø±ÙŠØ¨Ø©", "Ù…Ø¬Ø§Ø¹Ø©", "Ø¬Ø¨Ø§ÙŠØ©", "Ø®Ø±Ø§Ø¬"]):
            return "Ø§Ù‚ØªØµØ§Ø¯"
        elif any(w in text_lower for w in ["Ù…Ø¯ÙŠÙ†Ø©", "Ø´Ø§Ø±Ø¹", "Ø³ÙˆÙ‚", "Ø­ÙŠ"]):
            return "Ø­Ø¶Ø±ÙŠ"
        elif any(w in text_lower for w in ["Ø¨Ù†Ø§Ø¡", "Ù…Ø³Ø¬Ø¯", "Ø¯Ø§Ø±", "Ù‚ØµØ±"]):
            return "Ø¹Ù…Ø§Ø±Ø©"
        elif any(w in text_lower for w in ["ØªØ§Ø¬Ø±", "ØªØ¬Ø§Ø±Ø©", "Ø¨ÙŠØ¹", "Ø´Ø±Ø§Ø¡"]):
            return "ØªØ¬Ø§Ø±Ø©"
        elif any(w in text_lower for w in ["Ù‚Ø§Ø¶ÙŠ", "Ø­ÙƒÙ…", "Ø¯Ø¹ÙˆÙ‰", "Ø´Ù‡Ø§Ø¯Ø©"]):
            return "Ù‚Ø¶Ø§Ø¡"
        elif any(w in text_lower for w in ["Ø­Ø±Ø¨", "ØºØ²Ùˆ", "Ø¬Ù‡Ø§Ø¯", "Ù‚ØªØ§Ù„"]):
            return "Ø­Ø±Ø¨"
        elif any(w in text_lower for w in ["Ø¨Ø­Ø±", "Ø³ÙÙŠÙ†Ø©", "Ù…ÙŠÙ†Ø§Ø¡"]):
            return "Ø¨Ø­Ø±ÙŠ"
        elif any(w in text_lower for w in ["Ø¹ÙŠØ¯", "Ø§Ø­ØªÙØ§Ù„", "Ù…ÙˆÙ„Ø¯"]):
            return "Ø§Ø­ØªÙØ§Ù„Ø§Øª"
        elif any(w in text_lower for w in ["Ø·Ø¹Ø§Ù…", "Ø£ÙƒÙ„", "Ø·Ø¨Ø®"]):
            return "Ø·Ø¹Ø§Ù…"
        elif any(w in text_lower for w in ["Ø«ÙˆØ¨", "Ù†Ø³ÙŠØ¬", "Ø­ÙŠØ§ÙƒØ©"]):
            return "Ù†Ø³ÙŠØ¬"
        elif any(w in text_lower for w in ["Ù…ÙˆØ³ÙŠÙ‚Ù‰", "ØºÙ†Ø§Ø¡", "Ø¢Ù„Ø©"]):
            return "Ù…ÙˆØ³ÙŠÙ‚Ù‰"
        elif any(w in text_lower for w in ["Ø¹Ø·Ø±", "Ø¨Ø®ÙˆØ±", "Ø·ÙŠØ¨"]):
            return "Ø¹Ø·ÙˆØ±"
        elif any(w in text_lower for w in ["Ø´Ø±Ø·Ø©", "Ø­Ø±Ø§Ø³Ø©", "Ø¯ÙˆØ±ÙŠØ©"]):
            return "Ø´Ø±Ø·Ø©"
        elif any(w in text_lower for w in ["Ù…ÙˆØª", "Ø¯ÙÙ†", "Ø¬Ù†Ø§Ø²Ø©"]):
            return "Ù…ÙˆØª"
        elif any(w in text_lower for w in ["Ø²ÙˆØ§Ø¬", "Ù†ÙƒØ§Ø­", "Ø¹Ø±Ø³"]):
            return "Ø²ÙˆØ§Ø¬"
        elif any(w in text_lower for w in ["Ø·ÙÙ„", "ØµØ¨ÙŠ", "Ù„Ø¹Ø¨"]):
            return "Ø·ÙÙˆÙ„Ø©"
        elif any(w in text_lower for w in ["Ø·Ø¨", "Ø¯ÙˆØ§Ø¡", "Ù…Ø±Ø¶"]):
            return "ØµØ­Ø©"
        elif any(w in text_lower for w in ["Ø­Ù…Ø§Ù…", "ØºØ³Ù„", "Ù†Ø¸Ø§ÙØ©"]):
            return "Ø­Ù…Ø§Ù…Ø§Øª"
        elif any(w in text_lower for w in ["Ø³Ø­Ø±", "Ø´Ø¹ÙˆØ°Ø©", "ØªÙ†Ø¬ÙŠÙ…"]):
            return "Ø³Ø­Ø±"
        elif any(w in text_lower for w in ["Ù…ÙˆØ³Ù…", "ÙØµÙ„", "Ù…Ù†Ø§Ø®"]):
            return "Ù…ÙˆØ§Ø³Ù…"
        else:
            return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    async def process_and_distribute_batch(self, batch_size=1000):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªÙˆØ²ÙŠØ¹ Ø°ÙƒÙŠ"""
        
        query = f"""
        SELECT chunk_id, record_id, text
        FROM `iqraa-12.diwan_iqraa_v2.openiti_chunks`
        WHERE chunk_id NOT IN (
            SELECT chunk_id FROM `iqraa-12.diwan_iqraa_v2.classifications_unified`
        )
        LIMIT {batch_size}
        """
        
        rows = list(self.bq_client.query(query).result())
        
        if not rows:
            logger.info("âœ… ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù…ÙØ¹Ø§Ù„Ø¬Ø©!")
            return False
        
        logger.info(f"ï¿½ï¿½ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØªÙˆØ²ÙŠØ¹ {len(rows)} Ù†Øµ...")
        
        processed_results = []
        distribution_map = {}
        
        for row in rows:
            try:
                # Ù…Ø¹Ø§Ù„Ø¬Ø©
                inputs = self.tokenizer(row.text[:512], return_tensors="pt", truncation=True, max_length=512)
                
                with torch.no_grad():
                    outputs = self.model(**inputs)
                
                # ØªØµÙ†ÙŠÙ
                domain = self.simple_classify(row.text)
                
                result = {
                    "chunk_id": row.chunk_id,
                    "record_id": row.record_id,
                    "text": row.text,
                    "camelbert_processed": True,
                    "final_domain": domain,
                    "processed_at": datetime.now().isoformat()
                }
                
                processed_results.append(result)
                
                # ØªØ¬Ù…ÙŠØ¹ Ù„Ù„ØªÙˆØ²ÙŠØ¹ (ÙÙ‚Ø· Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©)
                if domain in self.DOMAIN_TO_EMPTY_TABLE:
                    if domain not in distribution_map:
                        distribution_map[domain] = []
                    distribution_map[domain].append(result)
                else:
                    # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ù…Ù„ÙˆØ¡Ø© - Ù†ØªØ®Ø·Ø§Ù‡Ø§
                    self.tracker["skipped"] += 1
                
                self.tracker["processed"] += 1
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£: {e}")
        
        # Ø­ÙØ¸ ÙÙŠ classifications_unified
        if processed_results:
            self.bq_client.insert_rows_json(
                "iqraa-12.diwan_iqraa_v2.classifications_unified",
                processed_results
            )
        
        # Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ© ÙÙ‚Ø·
        for domain, results in distribution_map.items():
            target_table = self.get_target_table(domain)
            
            try:
                errors = self.bq_client.insert_rows_json(target_table, results)
                
                if not errors:
                    self.tracker["distributed"] += len(results)
                    logger.info(f"   âœ… ÙˆÙØ²Ù‘Ø¹ {len(results)} Ù†Øµ â†’ {domain}")
                else:
                    logger.error(f"   âŒ ÙØ´Ù„ {domain}: {errors[0]['errors'][0]['message']}")
                    
            except Exception as e:
                logger.error(f"   âŒ Ø®Ø·Ø£ {domain}: {e}")
        
        # ØªÙ‚Ø±ÙŠØ±
        if self.tracker["processed"] % 10000 == 0:
            logger.info(f"ğŸ“Š Ù…Ø¹Ø§Ù„Ø¬: {self.tracker['processed']:,} | Ù…ÙˆØ²Ø¹: {self.tracker['distributed']:,} | Ù…ØªØ®Ø·Ù‰: {self.tracker['skipped']:,}")
        
        return True
    
    async def run(self):
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø°ÙƒÙŠ...")
        logger.info(f"   Ø§Ù„Ù‡Ø¯Ù: 157,870,756 Ù†Øµ")
        logger.info(f"   Ø§Ù„ØªÙˆØ²ÙŠØ¹: Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ© (179) ÙÙ‚Ø·")
        
        while True:
            has_more = await self.process_and_distribute_batch(1000)
            
            if not has_more:
                break
        
        logger.info("âœ… Ø§ÙƒØªÙ…Ù„!")


if __name__ == "__main__":
    distributor = SmartDistributor()
    asyncio.run(distributor.run())

